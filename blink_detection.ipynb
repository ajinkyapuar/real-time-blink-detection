{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 6>**Detect eye blinks using Pupil Labs' blink detection pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Alpha Lab guide that accompanies this notebook can be found here: https://docs.pupil-labs.com/alpha-lab/blink-detection/<br><br>\n",
    "For more information on the technical details, you may want to read the accompanying <A HREF=\"https://docs.google.com/document/d/1JLBhC7fmBr6BR59IT3cWgYyqiaM8HLpFxv5KImrN-qE/export?format=pdf\">white paper</A>.<br><br>\n",
    "You can find detailed instructions on how to install all requirements in the README of this repository."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<font size = 5>Part 1:** Offline blink detection</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s start by importing the relevant modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blink_detector import blink_detection_pipeline\n",
    "from blink_detector.helper import preprocess_recording\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the path to the example recording for analysis. In case you would like to analyze a recording of your own, replace `recording_path` with the path to your recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_path = \"blink_detector/data/blinkdetection-87dc1c8a\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must first extract individual eye camera frames from the recording and apply some minor preprocessing. Given our example recording is from a Neon device, we set `is_neon` parameter to `True`. If you’re testing the blink detection pipeline with an Invisible recording, simply change this parameter to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_eye_images, right_eye_images, ts = preprocess_recording(\n",
    "    recording_path, is_neon=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to detect eye blinks in the recording, we can now call 'blink_detection_pipeline', a high-level function that calls a series of subroutines that implement the steps outlined in the white paper. We pass the extracted left and right eye video frames as well as the corresponding timestamps along and it outputs the detected blink events. Depending on your computational resources and the duration of the recording, this might take a short while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "blink_events = list(blink_detection_pipeline(left_eye_images, right_eye_images, ts))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having extracted the detected blink events, we can now print a few interesting blink statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Number of blinks: {len(blink_events)}\"\n",
    "\n",
    "    f\"\\nBlink rate [in Hz]: {len(blink_events) / ((ts[-1] - ts[0])/1e9):.2f}\"\n",
    "\n",
    "    f\"\\nAvg. blink duration [in sec]: {np.mean([blink.blink_duration_s for blink in blink_events]):.3f}\"\n",
    "\n",
    "    f\"\\nAvg. eyelid closing duration [in sec]: {np.mean([blink.eyelid_closing_duration_s for blink in blink_events]):.3f}\"\n",
    "\n",
    "    f\"\\nAvg. eyelid opening duration [in sec]: {np.mean([blink.eyelid_opening_duration_s for blink in blink_events]):.3f}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>That's it!</b> As you see, it is fairly straightforward to apply the blink detection pipeline and extract a number of interesting parameters.\n",
    "\n",
    "To round off the first segment of this tutorial, we will present a visual representation of the detected blinks, providing some insights into their temporal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from blink_detector.helper import visualize_blink_events\n",
    "\n",
    "# Limit the visualization to the first 100 s \n",
    "start_interval = 0\n",
    "end_interval = 120\n",
    "\n",
    "visualize_blink_events(blink_events, ts, start_interval, end_interval)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, you have finished the first part of this tutorial! Next, we'll delve into using Pupil Lab's Realtime Python API to carry out blink detection in realtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=5> **Part 2:** Blink detection in real time using Pupil Lab's Realtime Python API</font>\n",
    "\n",
    "In this section we will walk you through detecting eye blinks in near-realtime using <A HREF=\"https://pupil-labs-realtime-api.readthedocs.io/en/stable/\"><b>Pupil Lab's Real Time API</b></A>. \n",
    "\n",
    "Note that the temporal resolution of the blink detection is inherently limited by some of the (post-)processing parameters outlined in the [white paper](https://docs.google.com/document/d/1JLBhC7fmBr6BR59IT3cWgYyqiaM8HLpFxv5KImrN-qE/export?format=pdf). Moreover, the demands of the image processing can further impede performance. Consequently, there will be an inherent delay in blink detection, which makes it *near*-realtime rather than truly realtime."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have successfully set up your environment, let’s first import all the required modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import deque\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "from pupil_labs.realtime_api.simple import discover_one_device, discover_devices\n",
    "from blink_detector.blink_detector import blink_detection_pipeline\n",
    "from blink_detector.helper import (\n",
    "    stream_images_and_timestamps,\n",
    "    update_array,\n",
    "    compute_blink_rate,\n",
    "    plot_blink_rate,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to setup the real time API. We use Python's *asyncio* to implement asynchronous communication. In some environments, for example when working with Jupyter notebooks, asyncio won't work out of the box. We will make use of *nest_asyncio*, which allows *asyncio* to work also within Jupyter notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = discover_one_device()\n",
    "# if you have more than one device\n",
    "# devices = discover_devices(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the device name and its IP helps to make sure that the discovered device is indeed <br>\n",
    "the device you would like to connect with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone IP address: 192.168.20.88\n",
      "Phone name: Tom1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Phone IP address: {device.phone_ip}\")\n",
    "print(f\"Phone name: {device.phone_name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>**2.1.** Real-time blink rate since start of recording and over the last 30s</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will show you how to utilize the Realtime API in combination with the blink detection pipeline in order to perform realtime blink-rate estimation.\n",
    "<br><br>**Limitation:** As the blink detection pipeline is a generator object, it will block execution of the code until a blink event is yielded. This means that any computation that is carried out within the for-loop will only execute once a blink occurs. This means that blink rate can only be updated once a blink is detected. In order to get a continous readout of blink rate, one possible way to achieve this is via multi-threading, where one thread executes the blink deteciton pipeline and a second thread updates the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to re-initialize the streams as the previous ones have been exhausted\n",
    "left_images, right_images, timestamps = stream_images_and_timestamps(\n",
    "    device, is_neon=True\n",
    ")\n",
    "\n",
    "# let's keep track of the last 100 blinks\n",
    "blink_times = np.zeros(100)\n",
    "avg_blink_rate = np.zeros(100)\n",
    "blink_rate_last_30s = np.zeros(100)\n",
    "\n",
    "blink_counter = 0\n",
    "starting_time = time.time()\n",
    "\n",
    "while True:\n",
    "\n",
    "    blink_event = next(blink_detection_pipeline(left_images, right_images, timestamps))\n",
    "    \n",
    "    blink_counter += 1\n",
    "\n",
    "    elapsed_time = blink_event.start_time / 1e9 - starting_time\n",
    "\n",
    "    blink_times = update_array(blink_times, elapsed_time)\n",
    "\n",
    "    avg_blink_rate = update_array(\n",
    "        avg_blink_rate, compute_blink_rate(blink_counter, elapsed_time)\n",
    "    )\n",
    "\n",
    "    blink_counter_last_30s = np.sum(blink_times > max(blink_times[0] - 30, 0))\n",
    "\n",
    "    blink_rate_last_30s = update_array(\n",
    "        blink_rate_last_30s, blink_counter_last_30s / min(30, blink_times[0])\n",
    "    )\n",
    "\n",
    "    plot_blink_rate(blink_times, avg_blink_rate, blink_rate_last_30s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>**2.2.** Toggle recordings remotely through eye blinks</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will write a routine that detects a rapid sequence of three eye blinks. Upon detection of said sequence, the companion device will initiate a new recording or stop an ongoing one. \n",
    "\n",
    "If the default temporal interval (1.0 seconds) in which the three blinks must occur is too short (or too long) for your purpose, feel free to adjust the `time_inverval` parameter. Considering that the device requires a brief moment to initiate a recording, it’s essential to ensure a minimum time lapse between the initiation and the subsequent termination of a recording. Hence, we’ll enforce a waiting period of 0.5 seconds to avoid any potential conflicts between consecutive commands.\n",
    "\n",
    "In this example, the recording will be canceled (discarded). If you want to stop and then upload the recording to Pupil Cloud, you can `device.recording_cancel()` with `device.recording_stop_and_save()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_images, right_images, timestamps = stream_images_and_timestamps(\n",
    "    device, is_neon=True\n",
    ")\n",
    "\n",
    "# initialize a deque with N zeros (N: number of successive blinks)\n",
    "blink_queue = deque(maxlen=3)\n",
    "blink_queue.extend(np.zeros(3))\n",
    "\n",
    "# time interval within which the N blinks must occur\n",
    "time_interval = 1.0\n",
    "\n",
    "blink_event_stream = blink_detection_pipeline(left_images, right_images, timestamps)\n",
    "\n",
    "device_is_recording = False\n",
    "\n",
    "while True:\n",
    "    \n",
    "    blink_event = next(blink_event_stream)\n",
    "    blink_queue.append(blink_event.start_time / 1e9)\n",
    "    \n",
    "    toggle_recording = blink_queue[-1] - blink_queue[0] < time_interval\n",
    "\n",
    "    if toggle_recording:\n",
    "        if device_is_recording:\n",
    "            if time.time() - start_of_recording < 0.5:\n",
    "                print(\"Time between start and stop of recording is too short.\")\n",
    "                time.sleep(0.5)\n",
    "            print(\"Stop recording\")\n",
    "            device.recording_cancel()\n",
    "            device_is_recording = False\n",
    "        else:\n",
    "            print(\"Start recording\")\n",
    "            device.recording_start()\n",
    "            device_is_recording = True\n",
    "            start_of_recording = time.time()\n",
    "            \n",
    "        toggle_recording = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tom_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
